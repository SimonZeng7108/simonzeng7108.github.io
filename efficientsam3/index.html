<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="EfficientSAM3 distills SAM1, SAM2, and SAM3 into lightweight models that bring promptable concept segmentation to edge devices.">
  <meta name="keywords" content="EfficientSAM3, SAM3, segmentation, knowledge distillation, edge AI, promptable concept segmentation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EfficientSAM3</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg?v=2">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://simonzeng7108.github.io/about/">
        <span class="icon">
          <i class="fas fa-user"></i>
        </span>
        <span>Home Page</span>
      </a>
    </div>
  </div>
</nav>

<section class="hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <span class="tag is-success is-light">âœ“ Stage 1 image encoder weights released!</span>
          <h1 class="title is-1 publication-title">EfficientSAM3: Progressive Hierarchical Knowledge Distillation from SAM1, SAM2 &amp; SAM3</h1>
          <p class="is-size-5">Chengxi Simon Zeng, Yuxuan Jiang, Aaron Zhang Â· Visual Information Lab, University of Bristol</p>
          <div class="buttons is-centered mt-5">
            <a class="button is-dark is-rounded" href="https://github.com/SimonZeng7108/efficientsam3">
              <span class="icon"><i class="fab fa-github"></i></span>
              <span>GitHub</span>
            </a>
            <a class="button is-link is-rounded" href="https://huggingface.co/Simon7108528/EfficientSAM3">
            <span class="icon huggingface-icon">ðŸ¤—</span>
              <span>Weights</span>
            </a>
            <a class="button is-info is-rounded" href="#model-zoo">
              <span class="icon"><i class="fas fa-database"></i></span>
              <span>Model Zoo</span>
            </a>
            <a class="button is-danger is-rounded" href="https://arxiv.org/abs/2511.15833">
              <span class="icon"><i class="ai ai-arxiv"></i></span>
              <span>arXiv</span>
            </a>
            <a class="button is-primary is-rounded" href="https://discord.gg/Vd2gXNE8">
              <span class="icon"><i class="fab fa-discord"></i></span>
              <span>Discord</span>
            </a>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-two-thirds">
        <h2 class="title is-3">Why EfficientSAM3?</h2>
        <div class="content has-text-justified">
          <p>SAM3 delivers Promptable Concept Segmentation (PCS) by combining semantic understanding and temporal tracking, yet its massive backbone and dense memory bank make on-device deployment impractical. EfficientSAM3 compresses SAM1, SAM2, and SAM3 into a family of lightweight student models tailored for edge hardware without sacrificing PCS quality.</p>
        </div>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-three-quarters">
        <figure class="image">
          <img src="./static/images/efficientsam3_full.svg?v=2" alt="EfficientSAM3 architecture diagram">
        </figure>
      </div>
    </div>
  </div>
</section>

<section class="section is-light">
  <div class="container is-max-desktop">
    <div class="columns">
      <div class="column">
        <h3 class="title is-4">Updates</h3>
        <ul>
          <li><strong>2025-12-02:</strong> Stage 1 image encoder weights released for all 9 variants (RepViT, TinyViT, EfficientViT) - distilled on 1% of SA-1B dataset. Available via Google Drive and Hugging Face.</li>
          <li><strong>2025-10-18:</strong> Project announced.</li>
        </ul>
      </div>
      <div class="column">
        <h3 class="title is-4">Highlights</h3>
        <ul>
          <li>Image encoders distilled into RepViT, TinyViT, and EfficientViT families.</li>
          <li>Text encoders distilled into MobileCLIP variants (up to 87.96% smaller than SAM3's 354M text encoder).</li>
          <li>Perceiver-based memory compression aligned with SAM2 temporal tracking.</li>
          <li>ONNX/CoreML support for real-time mobile, embedded, and desktop deployment.</li>
        </ul>
      </div>
      <div class="column">
        <h3 class="title is-4">Resources</h3>
        <ul>
          <li><a href="https://github.com/SimonZeng7108/efficientsam3#readme">Project README</a> (installation, inference, training)</li>
          <li><a href="https://github.com/SimonZeng7108/efficientsam3/blob/main/README_dataset.md">Dataset setup guide</a></li>
          <li><a href="https://arxiv.org/abs/2511.15833">arXiv</a></li>
        </ul>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>SAM3 brought promptable concept segmentation to production scale, but its computational footprint blocks latency-sensitive applications. EfficientSAM3 progressively distills SAM3 into lightweight architectures that maintain PCS quality on edge devices.</p>
          <p>We employ a three-stage curriculum: (1) encoder distillation on SA-1B with prompt-in-the-loop supervision, (2) temporal memory distillation on SA-V using a compact Perceiver module, and (3) end-to-end fine-tuning on official SAM3 concept segmentation data. The resulting students deliver real-time segmentation, tracking, and prompt handling on resource-constrained platforms.</p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section is-light">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Three-Stage Progressive Distillation</h2>
    <div class="columns">
      <div class="column">
        <div class="box">
          <h3 class="title is-5 stage-box-title">Stage 1 Â· Compact Encoder</h3>
          <p>Align nine student backbones (RepViT, TinyViT, EfficientViT) with the SAM3 encoder using SA-1B and prompt-in-the-loop supervision.</p>
        </div>
      </div>
      <div class="column">
        <div class="box">
          <h3 class="title is-5 stage-box-title">Stage 2 Â· Temporal Memory</h3>
          <p>Compress SAM3's dense video memory into a Perceiver-based module distilled on SA-V, enabling efficient multi-frame reasoning.</p>
        </div>
      </div>
      <div class="column">
        <div class="box">
          <h3 class="title is-5 stage-box-title">Stage 3 Â· Promptable PCS</h3>
          <p>Jointly fine-tune encoder, memory, and decoder on SAM3 data to preserve promptable concept segmentation quality.</p>
        </div>
      </div>
    </div>
    <p class="has-text-centered">tl;dr: Stage 1 distills encoder on SAM1 data Â· Stage 2 aligns memory on SAM2 data Â· Stage 3 fine-tunes PCS on SAM3 data.</p>
  </div>
</section>

<section class="section" id="get-started">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Get Started</h2>
    <div class="columns">
      <div class="column">
        <h3 class="title is-5">Installation</h3>
        <div class="content">
          <pre><code>pip install -e ".[stage1]"</code></pre>
          <p>See the <a href="https://github.com/SimonZeng7108/efficientsam3#installation">installation guide</a> for full setup instructions.</p>
        </div>
      </div>
      <div class="column">
        <h3 class="title is-5">Quick Start</h3>
        <div class="content">
          <pre><code>model = build_efficientsam3_image_model(
    checkpoint_path="efficient_sam3_tinyvit_s.pt",
    backbone_type="tinyvit", model_name="5m"
)
processor = Sam3Processor(model)
inference_state = processor.set_image(image)
masks, scores, _ = model.predict_inst(
    inference_state, point_coords=points, 
    point_labels=labels
)</code></pre>
          <p>See <a href="https://github.com/SimonZeng7108/efficientsam3/blob/main/sam3/efficientsam3_examples/efficientsam3_for_sam1_task_example.py">example script</a> for details.</p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section is-light" id="model-zoo">
  <div class="container is-max-desktop">
    <h2 class="title is-3">EfficientSAM3 Model Zoo &amp; Weight Release</h2>
    <p>Stage 1 image encoder weights (distilled from SAM3 image encoder) are now available via Google Drive and Hugging Face. Stage 2 and 3 weights coming soon.</p>
    
    <h3 class="title is-4 mt-5">Image Encoder Models</h3>
    <div class="table-container">
      <table class="table is-striped is-fullwidth">
        <thead>
          <tr>
            <th>Model</th>
            <th>Backbone</th>
            <th>Parameters</th>
            <th>Stage 1</th>
            <th>Stage 2</th>
            <th>Stage 3</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>ES-RV-S</strong></td>
            <td>RepViT-M0.9</td>
            <td>5.1M</td>
            <td><a href="https://drive.google.com/file/d/1lVvPPoIVDhCFGte-1E_dr4X5EKbE5xKq/view?usp=drive_link">GDrive</a> / <a href="https://huggingface.co/Simon7108528/EfficientSAM3/resolve/main/stage1_all_converted/efficient_sam3_repvit_s.pt">HF</a></td>
            <td>Planned</td>
            <td>Planned</td>
          </tr>
          <tr>
            <td><strong>ES-RV-M</strong></td>
            <td>RepViT-M1.1</td>
            <td>6.8M</td>
            <td><a href="https://drive.google.com/file/d/1JW3KiTnYF2r8nIijf8UXrKXJwf5D5s-5/view?usp=drive_link">GDrive</a> / <a href="https://huggingface.co/Simon7108528/EfficientSAM3/resolve/main/stage1_all_converted/efficient_sam3_repvit_m.pt">HF</a></td>
            <td>Planned</td>
            <td>Planned</td>
          </tr>
          <tr>
            <td><strong>ES-RV-L</strong></td>
            <td>RepViT-M2.3</td>
            <td>8.2M</td>
            <td><a href="https://drive.google.com/file/d/1ocAkz6DgkaKCKpLdalq2Ya8X6VIMrLLI/view?usp=drive_link">GDrive</a> / <a href="https://huggingface.co/Simon7108528/EfficientSAM3/resolve/main/stage1_all_converted/efficient_sam3_repvit_l.pt">HF</a></td>
            <td>Planned</td>
            <td>Planned</td>
          </tr>
          <tr>
            <td><strong>ES-TV-S</strong></td>
            <td>TinyViT-5M</td>
            <td>5.4M</td>
            <td><a href="https://drive.google.com/file/d/1CDfJTd2fTKJTV5nsfYLAV_CGMfQ-AWXS/view?usp=drive_link">GDrive</a> / <a href="https://huggingface.co/Simon7108528/EfficientSAM3/resolve/main/stage1_all_converted/efficient_sam3_tinyvit_s.pt">HF</a></td>
            <td>Planned</td>
            <td>Planned</td>
          </tr>
          <tr>
            <td><strong>ES-TV-M</strong></td>
            <td>TinyViT-11M</td>
            <td>11M</td>
            <td><a href="https://drive.google.com/file/d/1TX70zw7SduQRZP6hce6MIxEOsdoooZFB/view?usp=drive_link">GDrive</a> / <a href="https://huggingface.co/Simon7108528/EfficientSAM3/resolve/main/stage1_all_converted/efficient_sam3_tinyvit_m.pt">HF</a></td>
            <td>Planned</td>
            <td>Planned</td>
          </tr>
          <tr>
            <td><strong>ES-TV-L</strong></td>
            <td>TinyViT-21M</td>
            <td>21M</td>
            <td><a href="https://drive.google.com/file/d/19hyKjjZ4_8ldmxIAm6D8e8z89xX-M3hZ/view?usp=drive_link">GDrive</a> / <a href="https://huggingface.co/Simon7108528/EfficientSAM3/resolve/main/stage1_all_converted/efficient_sam3_tinyvit_l.pt">HF</a></td>
            <td>Planned</td>
            <td>Planned</td>
          </tr>
          <tr>
            <td><strong>ES-EV-S</strong></td>
            <td>EfficientViT-B0</td>
            <td>0.7M</td>
            <td><a href="https://drive.google.com/file/d/1EnA581iSExZRRWlI6oY-wXTgX4gESijG/view?usp=drive_link">GDrive</a> / <a href="https://huggingface.co/Simon7108528/EfficientSAM3/resolve/main/stage1_all_converted/efficient_sam3_efficientvit_s.pt">HF</a></td>
            <td>Planned</td>
            <td>Planned</td>
          </tr>
          <tr>
            <td><strong>ES-EV-M</strong></td>
            <td>EfficientViT-B1</td>
            <td>4.8M</td>
            <td><a href="https://drive.google.com/file/d/14CRA3LhquUkf8prrKfI1INyHtCw6buvm/view?usp=sharing">GDrive</a> / <a href="https://huggingface.co/Simon7108528/EfficientSAM3/resolve/main/stage1_all_converted/efficient_sam3_efficientvit_m.pt">HF</a></td>
            <td>Planned</td>
            <td>Planned</td>
          </tr>
          <tr>
            <td><strong>ES-EV-L</strong></td>
            <td>EfficientViT-B2</td>
            <td>15M</td>
            <td><a href="https://drive.google.com/file/d/1Zg0Er0LwYYNCFJezSUSlQ8L645cR1OhN/view?usp=drive_link">GDrive</a> / <a href="https://huggingface.co/Simon7108528/EfficientSAM3/resolve/main/stage1_all_converted/efficient_sam3_efficientvit_l.pt">HF</a></td>
            <td>Planned</td>
            <td>Planned</td>
          </tr>
        </tbody>
      </table>
    </div>
    <p class="notification is-info is-light mt-3"><strong>Note (2025/12/02):</strong> The current Stage 1 image encoder weights are distilled on 1% of the SA-1B dataset.</p>

    <h3 class="title is-4 mt-5">Text Encoder Models</h3>
    <div class="table-container">
      <table class="table is-striped is-fullwidth">
        <thead>
          <tr>
            <th>Model</th>
            <th>Backbone</th>
            <th>Parameters</th>
            <th>Stage 1</th>
            <th>Stage 2</th>
            <th>Stage 3</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>ES-MC-S</strong></td>
            <td>MobileCLIP-S0</td>
            <td>42.57M</td>
            <td>Planned</td>
            <td>Planned</td>
            <td>Planned</td>
          </tr>
          <tr>
            <td><strong>ES-MC-M</strong></td>
            <td>MobileCLIP-S1</td>
            <td>63.56M</td>
            <td>Planned</td>
            <td>Planned</td>
            <td>Planned</td>
          </tr>
          <tr>
            <td><strong>ES-MC-L</strong></td>
            <td>MobileCLIP2-L</td>
            <td>123.6M</td>
            <td>Planned</td>
            <td>Planned</td>
            <td>Planned</td>
          </tr>
        </tbody>
      </table>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns">
      <div class="column">
        <h3 class="title is-4">Datasets</h3>
        <p>Dataset preparation scripts for COCO, DAVIS, LVIS, SA-1B, SA-V, LVOS, MOSE, and YouTube-VOS are located under <code>data/download_*.sh</code>. Refer to <a href="README_dataset.md">README_dataset.md</a> for detailed instructions.</p>
      </div>
      <div class="column">
        <h3 class="title is-4">Export &amp; Deployment</h3>
        <p>ONNX and CoreML export pipelines are under development to unlock mobile and cross-platform deployment. Follow the repository issues for progress updates.</p>
      </div>
    </div>
  </div>
</section>

<section class="section is-light">
  <div class="container is-max-desktop">
    <div class="columns">
      <div class="column">
        <h3 class="title is-4">Roadmap</h3>
        <ul>
          <li><span class="tag is-success is-light">âœ“ Completed</span> Release Stage 1 image encoder weights (distilled from SAM3 image encoder)</li>
          <li><span class="tag is-info is-light">In Progress</span> Release Stage 1 text encoder weights (distilled from SAM3 text encoder to MobileCLIP variants)</li>
          <li><span class="tag is-info is-light">Planned</span> Release Stage 1+ fine-tuned encoder weights (prompt-in-the-loop supervised fine-tuning)</li>
          <li><span class="tag is-info is-light">Planned</span> Release Stage 2 memory bank aligned models</li>
          <li><span class="tag is-info is-light">Planned</span> Release Stage 3 fine-tuned PCS models</li>
          <li><span class="tag is-info is-light">Planned</span> ONNX/CoreML export</li>
          <li><span class="tag is-info is-light">Planned</span> Interactive web demo</li>
        </ul>
      </div>
      <div class="column">
        <h3 class="title is-4">Call for Contributions</h3>
        <p>We welcome pull requests across the ecosystem:</p>
        <ul>
          <li>Efficient MedSAM3 integration and medical datasets</li>
          <li>Gradio demos, Vercel deployments, and Hugging Face Spaces</li>
          <li>Annotation tool support (X-AnyLabeling, AnyLabeling)</li>
          <li>iOS, Android, and NVCC-based desktop applications</li>
        </ul>
      </div>
    </div>
  </div>
</section>

<section class="section is-light">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Users</h2>
    <p class="has-text-centered">Organizations and projects using EfficientSAM3:</p>
    
    <div class="columns is-mobile is-multiline is-centered mt-5">
      <div class="column is-one-fifth-desktop is-one-third-tablet has-text-centered">
        <img src="./static/images/esa.png" alt="European Space Agency" style="height: 80px; margin-bottom: 10px;">
        <p><a href="https://www.esa.int/">European Space Agency</a></p>
      </div>
    </div>
    
    <div class="notification is-info is-light mt-5">
      <p><strong>Note:</strong> If you're using EfficientSAM3 in your work, please acknowledge us in your publications or projects. We're happy to promote your work here! Contact us to be featured in this section.</p>
    </div>
  </div>
</section>

<section class="section" id="citation">
  <div class="container is-max-desktop content">
    <h2 class="title">Citation</h2>
    <pre><code>@misc{zeng2025efficientsam3progressivehierarchicaldistillation,
  title={EfficientSAM3: Progressive Hierarchical Distillation for Video Concept Segmentation from SAM1, 2, and 3}, 
  author={Chengxi Zeng and Yuxuan Jiang and Gao Ge and Shuai Wang and Fan Aaron Zhang},
  year={2025},
  eprint={2511.15833},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2511.15833}, 
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/SimonZeng7108/efficientsam3">
        <i class="fab fa-github"></i>
      </a>
      <a class="icon-link" href="https://huggingface.co/Simon7108528/EfficientSAM3">
        <i class="ai ai-huggingface"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-centered">
          <p>This website follows the <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.</p>
          <p>Template adapted from <a href="https://github.com/nerfies/nerfies.github.io">nerfies.github.io</a> with attribution.</p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
